{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as Pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = Pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPart1 = unpickle(\"cifar-10-batches-py/data_batch_1\")\n",
    "dataPart2 = unpickle(\"cifar-10-batches-py/data_batch_2\")\n",
    "dataPart3 = unpickle(\"cifar-10-batches-py/data_batch_3\")\n",
    "dataPart4 = unpickle(\"cifar-10-batches-py/data_batch_4\")\n",
    "dataPart5 = unpickle(\"cifar-10-batches-py/data_batch_5\")\n",
    "dataPartTest = unpickle(\"cifar-10-batches-py/test_batch\")\n",
    "dataPartMeta = unpickle(\"cifar-10-batches-py/batches.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPart1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,  43,  50, ..., 140,  84,  72],\n",
       "       [154, 126, 105, ..., 139, 142, 144],\n",
       "       [255, 253, 253, ...,  83,  83,  84],\n",
       "       ...,\n",
       "       [ 71,  60,  74, ...,  68,  69,  68],\n",
       "       [250, 254, 211, ..., 215, 255, 254],\n",
       "       [ 62,  61,  60, ..., 130, 130, 131]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPart1[b'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = np.asarray([1, 2,3 ])\n",
    "[1] + row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDataToDF(dataDict):\n",
    "    dataFrame = pd.DataFrame(columns = ['Features / Colors'])\n",
    "    columnLabels = np.asarray(dataDict[b'labels'])\n",
    "    rowNumber = 0\n",
    "    for row in dataPart1[b'data']:\n",
    "        dataFrame.append(row)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([dataPart1[b'data'], dataPart2[b'data'], dataPart3[b'data'], dataPart4[b'data'], dataPart5[b'data']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.hstack([dataPart1[b'labels'], dataPart2[b'labels'], dataPart3[b'labels'], dataPart4[b'labels'], dataPart5[b'labels']])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel():\n",
    "    inputSize = 3072\n",
    "    hiddenLayer1 = 500\n",
    "    hiddenLayer2 = 200\n",
    "    hiddenLayer3 = 128\n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(3072, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(hiddenLayer1, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(hiddenLayer2, activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(hiddenLayer3, activation=\"relu\", name=\"layer4\"),\n",
    "        layers.Dense(hiddenLayer3, activation=\"relu\", name=\"layer5\"),\n",
    "        layers.Dense(10, activation=\"softmax\", name=\"layer6\"),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# keras.convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = makeModel()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy() # A parameter to do softmax implicitly from_logits\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001 * 2)\n",
    "model.compile(optimizer = optimizer, loss=loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLabelsToArray(labels):\n",
    "    newLabel = []\n",
    "    for label in labels:\n",
    "        newList= [0] *10\n",
    "        newList[label-1] = 1\n",
    "        newLabel.append(newList)\n",
    "    return np.array(newLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsArray = convertLabelsToArray(labels)\n",
    "labelsArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 144s 92ms/step - loss: 14.6383 - accuracy: 0.2134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe8b29c51f0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, labelsArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dataPartTest[b'data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3069"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n",
    "newPredictedLabels = convertPredictionsToLabels(predictions)\n",
    "accuracy_score(newPredictedLabels, dataPartTest[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.27403031e-04, 3.00849439e-03, 4.73574460e-01, ...,\n",
       "        1.28936235e-05, 1.75179949e-03, 9.19392258e-02],\n",
       "       [4.68452945e-02, 6.04702346e-03, 1.00187302e-01, ...,\n",
       "        2.02606004e-02, 8.33066239e-04, 8.07837248e-01],\n",
       "       [1.01903628e-04, 2.11095035e-08, 3.40662384e-03, ...,\n",
       "        3.40295658e-02, 1.15597449e-01, 1.87013805e-01],\n",
       "       ...,\n",
       "       [7.49693208e-05, 3.45682984e-08, 1.57634751e-03, ...,\n",
       "        8.24775780e-04, 8.34325179e-02, 9.13210988e-01],\n",
       "       [6.07584625e-05, 8.53977599e-06, 2.81433435e-03, ...,\n",
       "        1.34528995e-01, 1.07197827e-02, 7.58775055e-01],\n",
       "       [5.96306381e-05, 2.19296795e-04, 4.19890182e-03, ...,\n",
       "        5.39472909e-04, 5.12773730e-03, 9.15941224e-02]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertPredictionsToLabels(predictions):\n",
    "    return [np.argmax(row) + 1 for row in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 10,\n",
       " 7,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 3,\n",
       " 10,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 1,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 2,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 5,\n",
       " 6,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 2,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 5,\n",
       " 10,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 5,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 1,\n",
       " 10,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 5,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 5,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 3,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n",
    "predictedLabels = convertPredictionsToLabels(predictions)\n",
    "predictedLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1839"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictedLabels, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearSVC(random_state=0, max_iter=5000)\n",
    "# reduce dimensions using PCA\n",
    "#non-linear SVMS\n",
    "model1.fit(data, labels)\n",
    "# training_predictions = model.predict(mnist_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2391"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictedLabels = model1.predict(dataPartTest[b'data'])\n",
    "accuracy_score(predictedLabels, dataPartTest[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDeeperModel():\n",
    "    inputSize = 3072\n",
    "    hiddenLayer1 = 300\n",
    "    hiddenLayer2 = 100\n",
    "    hiddenLayer3 = 64\n",
    "    hiddenLayer4 = 64\n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(3072, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(hiddenLayer1, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(hiddenLayer2, activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(hiddenLayer3, activation=\"relu\", name=\"layer4\"),\n",
    "        layers.Dense(hiddenLayer4, activation=\"relu\", name=\"layer5\"),\n",
    "        layers.Dense(10, activation=\"softmax\", name=\"layer6\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModel = makeDeeperModel()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy() # A parameter to do softmax implicitly from_logits\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001 * 5)\n",
    "newModel.compile(optimizer = optimizer, loss=loss, metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 137s 87ms/step - loss: 21.7046 - accuracy: 0.2002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe8b19685e0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newModel.fit(data, labelsArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2421"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallerPredictions = newModel.predict(dataPartTest[b'data'])\n",
    "newPredictedLabels = convertPredictionsToLabels(smallerPredictions)\n",
    "accuracy_score(newPredictedLabels, dataPartTest[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonLinearSVM = NuSVC()\n",
    "nonLinearSVM.fit(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedLabels = nonLinearSVM.predict(dataPartTest[b'data'])\n",
    "accuracy_score(predictedLabels, dataPartTest[b'labels'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
